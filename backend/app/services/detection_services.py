# backend/app/services/detection_services.py
import os
import json
from pathlib import Path
import torch
import cv2
import numpy as np
from PIL import Image, ImageDraw, ImageFont
from ultralytics import YOLO
from transformers import pipeline
from qrdet import QRDetector
import time
from typing import List, Dict, Tuple, Optional
import easyocr

# === PATH CONFIGURATION ===
PROJECT_ROOT = Path(__file__).parent.parent.parent.parent
MODELS_DIR = PROJECT_ROOT / 'backend' / 'app' / 'models'
OUTPUT_DIR = PROJECT_ROOT / 'output'
OUTPUT_DIR.mkdir(exist_ok=True)

class AdvancedSignatureDetector:
    def __init__(self):
        print("üîÑ –ó–∞–≥—Ä—É–∑–∫–∞ —É–ª—É—á—à–µ–Ω–Ω–æ–≥–æ –¥–µ—Ç–µ–∫—Ç–æ—Ä–∞ –ø–æ–¥–ø–∏—Å–µ–π...")
        try:
            self.detector = pipeline(
                "object-detection",
                model="nickmuchi/yolos-small-finetuned-signature-verification",
                device=0 if torch.cuda.is_available() else -1
            )
        except Exception as e:
            print(f"‚ö†Ô∏è –û—Å–Ω–æ–≤–Ω–∞—è –º–æ–¥–µ–ª—å –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞: {e}, –∏—Å–ø–æ–ª—å–∑—É–µ–º fallback")
            self.detector = pipeline(
                "object-detection",
                model="mdefrance/yolos-base-signature-detection"
            )
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º OCR –¥–ª—è –ø–æ–∏—Å–∫–∞ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –ø–æ–¥—Å–∫–∞–∑–æ–∫
        self.reader = easyocr.Reader(['ru', 'en'])
        print("‚úÖ –£–ª—É—á—à–µ–Ω–Ω—ã–π –¥–µ—Ç–µ–∫—Ç–æ—Ä –ø–æ–¥–ø–∏—Å–µ–π –∑–∞–≥—Ä—É–∂–µ–Ω")
    
    def find_signature_text_regions(self, image: Image.Image) -> List[Dict]:
        """–ù–∞—Ö–æ–¥–∏—Ç –æ–±–ª–∞—Å—Ç–∏ —Å —Ç–µ–∫—Å—Ç–æ–º '–ø–æ–¥–ø–∏—Å—å', '–§.–ò.–û', 'signature' –∏ —Ç.–¥."""
        opencv_image = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)
        
        # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –∫–æ–Ω—Ç—Ä–∞—Å—Ç –¥–ª—è –ª—É—á—à–µ–≥–æ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ç–µ–∫—Å—Ç–∞
        lab = cv2.cvtColor(opencv_image, cv2.COLOR_BGR2LAB)
        lab[:, :, 0] = cv2.createCLAHE(clipLimit=2.0).apply(lab[:, :, 0])
        enhanced_image = cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)
        
        # –†–∞—Å–ø–æ–∑–Ω–∞–µ–º —Ç–µ–∫—Å—Ç
        results = self.reader.readtext(enhanced_image)
        
        signature_keywords = ['–ø–æ–¥–ø–∏—Å—å', '–ø–æ–¥–ø–∏—Å–∏', '—Ñ–∏–æ', '—Ñ.–∏.–æ', 'signature', 'signed', 'name']
        text_regions = []
        
        for (bbox, text, confidence) in results:
            text_lower = text.lower()
            if any(keyword in text_lower for keyword in signature_keywords) and confidence > 0.3:
                # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º bbox –≤ —Ñ–æ—Ä–º–∞—Ç [x1, y1, x2, y2]
                points = np.array(bbox).reshape(-1, 2)
                x1, y1 = points.min(axis=0)
                x2, y2 = points.max(axis=0)
                
                # –†–∞—Å—à–∏—Ä—è–µ–º –æ–±–ª–∞—Å—Ç—å –ø–æ–∏—Å–∫–∞ (–≤–Ω–∏–∑ –æ—Ç —Ç–µ–∫—Å—Ç–∞)
                height = y2 - y1
                expanded_region = [
                    max(0, int(x1 - 20)),
                    max(0, int(y2 - 10)),  # –ù–∞—á–∏–Ω–∞–µ–º –Ω–µ–º–Ω–æ–≥–æ –≤—ã—à–µ —Ç–µ–∫—Å—Ç–∞
                    min(image.width, int(x2 + 20)),
                    min(image.height, int(y2 + height * 3))  # –ò—â–µ–º –ø–æ–¥–ø–∏—Å—å –Ω–∏–∂–µ —Ç–µ–∫—Å—Ç–∞
                ]
                
                text_regions.append({
                    'bbox': expanded_region,
                    'text': text,
                    'confidence': confidence
                })
                print(f"üìù –ù–∞–π–¥–µ–Ω —Ç–µ–∫—Å—Ç –ø–æ–¥–ø–∏—Å–∏: '{text}' –≤ –æ–±–ª–∞—Å—Ç–∏ {expanded_region}")
        
        return text_regions
    
    def detect_in_region(self, image: Image.Image, region: List[int]) -> List[Dict]:
        """–î–µ—Ç–µ–∫—Ç–∏—Ä—É–µ—Ç –ø–æ–¥–ø–∏—Å–∏ –≤ —É–∫–∞–∑–∞–Ω–Ω–æ–π –æ–±–ª–∞—Å—Ç–∏"""
        x1, y1, x2, y2 = region
        region_image = image.crop((x1, y1, x2, y2))
        
        if region_image.size[0] == 0 or region_image.size[1] == 0:
            return []
        
        # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –∫–æ–Ω—Ç—Ä–∞—Å—Ç –≤ –æ–±–ª–∞—Å—Ç–∏
        enhancer = ImageEnhance.Contrast(region_image)
        region_image = enhancer.enhance(2.0)
        
        results = self.detector(region_image)
        detections = []
        
        for result in results:
            if result['score'] > 0.25:  # –ë–æ–ª–µ–µ –Ω–∏–∑–∫–∏–π –ø–æ—Ä–æ–≥ –¥–ª—è —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –æ–±–ª–∞—Å—Ç–µ–π
                box = result['box']
                # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –æ–±—Ä–∞—Ç–Ω–æ –∫ –∏—Å—Ö–æ–¥–Ω–æ–º—É –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é
                absolute_bbox = [
                    x1 + box['xmin'],
                    y1 + box['ymin'],
                    x1 + box['xmax'],
                    y1 + box['ymax']
                ]
                
                detections.append({
                    'label': 'signature',
                    'bbox': absolute_bbox,
                    'confidence': result['score'],
                    'area': (box['xmax'] - box['xmin']) * (box['ymax'] - box['ymin']),
                    'source': 'text_guided'
                })
        
        return detections
    
    def detect_signatures(self, image: Image.Image) -> List[Dict]:
        start_time = time.time()
        
        if image.mode != 'RGB':
            image = image.convert('RGB')
        
        # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è —Ä–∞–∑–º–µ—Ä–∞
        max_size = 1024
        if max(image.size) > max_size:
            ratio = max_size / max(image.size)
            new_size = (int(image.size[0] * ratio), int(image.size[1] * ratio))
            image = image.resize(new_size, Image.Resampling.LANCZOS)
        
        all_detections = []
        
        # –®–∞–≥ 1: –ü–æ–∏—Å–∫ –ø–æ —Ç–µ–∫—Å—Ç–æ–≤—ã–º –ø–æ–¥—Å–∫–∞–∑–∫–∞–º
        print("üîç –ü–æ–∏—Å–∫ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —É–∫–∞–∑–∞—Ç–µ–ª–µ–π –ø–æ–¥–ø–∏—Å–µ–π...")
        text_regions = self.find_signature_text_regions(image)
        
        for region in text_regions:
            region_detections = self.detect_in_region(image, region['bbox'])
            all_detections.extend(region_detections)
        
        # –®–∞–≥ 2: –û–±—â–∏–π –ø–æ–∏—Å–∫ –ø–æ –≤—Å–µ–º—É –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é (—Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ –ø–æ —Ç–µ–∫—Å—Ç—É)
        if not all_detections:
            print("üîç –û–±—â–∏–π –ø–æ–∏—Å–∫ –ø–æ–¥–ø–∏—Å–µ–π...")
            results = self.detector(image)
            
            for result in results:
                if result['score'] > 0.3:
                    box = result['box']
                    detections.append({
                        'label': 'signature',
                        'bbox': [box['xmin'], box['ymin'], box['xmax'], box['ymax']],
                        'confidence': result['score'],
                        'area': (box['xmax'] - box['xmin']) * (box['ymax'] - box['ymin']),
                        'source': 'general'
                    })
        
        # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
        filtered_detections = self._remove_overlapping_detections(all_detections)
        
        print(f"‚è±Ô∏è –î–µ—Ç–µ–∫—Ü–∏—è –ø–æ–¥–ø–∏—Å–µ–π: {time.time() - start_time:.2f}s, –Ω–∞–π–¥–µ–Ω–æ: {len(filtered_detections)}")
        return filtered_detections
    
    def _remove_overlapping_detections(self, detections: List[Dict], iou_threshold: float = 0.5) -> List[Dict]:
        """–£–±–∏—Ä–∞–µ—Ç –ø–µ—Ä–µ—Å–µ–∫–∞—é—â–∏–µ—Å—è –¥–µ—Ç–µ–∫—Ü–∏–∏"""
        if not detections:
            return []
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
        detections.sort(key=lambda x: x['confidence'], reverse=True)
        filtered = []
        
        for i, det in enumerate(detections):
            keep = True
            for kept in filtered:
                iou = self._calculate_iou(det['bbox'], kept['bbox'])
                if iou > iou_threshold:
                    keep = False
                    break
            if keep:
                filtered.append(det)
        
        return filtered
    
    def _calculate_iou(self, box1: List[float], box2: List[float]) -> float:
        """–í—ã—á–∏—Å–ª—è–µ—Ç Intersection over Union"""
        x11, y1_1, x2_1, y2_1 = box1
        x1_2, y1_2, x2_2, y2_2 = box2
        
        # –í—ã—á–∏—Å–ª—è–µ–º –ø–ª–æ—â–∞–¥—å –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏—è
        xi1 = max(x1_1, x1_2)
        yi1 = max(y1_1, y1_2)
        xi2 = min(x2_1, x2_2)
        yi2 = min(y2_1, y2_2)
        inter_area = max(0, xi2 - xi1) * max(0, yi2 - yi1)
        
        # –í—ã—á–∏—Å–ª—è–µ–º –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ
        box1_area = (x2_1 - x1_1) * (y2_1 - y1_1)
        box2_area = (x2_2 - x1_2) * (y2_2 - y1_2)
        union_area = box1_area + box2_area - inter_area
        
        return inter_area / union_area if union_area > 0 else 0

class RobustQRCodeDetector:
    def __init__(self):
        print("üîÑ –ó–∞–≥—Ä—É–∑–∫–∞ —É–ª—É—á—à–µ–Ω–Ω–æ–≥–æ –¥–µ—Ç–µ–∫—Ç–æ—Ä–∞ QR-–∫–æ–¥–æ–≤...")
        self.detector = QRDetector(model_size='s')
        print("‚úÖ –î–µ—Ç–µ–∫—Ç–æ—Ä QR-–∫–æ–¥–æ–≤ –∑–∞–≥—Ä—É–∂–µ–Ω")
    
    def detect_qr_codes(self, image: Image.Image) -> List[Dict]:
        start_time = time.time()
        
        opencv_image = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)
        
        try:
            # –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –¥–µ—Ç–µ–∫—Ü–∏–∏
            gray = cv2.cvtColor(opencv_image, cv2.COLOR_BGR2GRAY)
            clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
            enhanced = clahe.apply(gray)
            
            detections = self.detector.detect(image=enhanced, is_bgr=False)
            results = []
            
            for detection in detections:
                if hasattr(detection, 'bbox_xyxy'):
                    bbox = detection.bbox_xyxy
                    confidence = detection.confidence
                elif isinstance(detection, dict):
                    bbox = detection['bbox_xyxy']
                    confidence = detection['confidence']
                else:
                    continue
                
                if confidence > 0.1:  # –ù–∏–∑–∫–∏–π –ø–æ—Ä–æ–≥ –¥–ª—è QR-–∫–æ–¥–æ–≤
                    results.append({
                        'label': 'qr_code',
                        'bbox': [int(x) for x in bbox],
                        'confidence': float(confidence),
                        'area': (bbox[2] - bbox[0]) * (bbox[3] - bbox[1])
                    })
            
            print(f"‚è±Ô∏è –î–µ—Ç–µ–∫—Ü–∏—è QR: {time.time() - start_time:.2f}s, –Ω–∞–π–¥–µ–Ω–æ: {len(results)}")
            return results
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –¥–µ—Ç–µ–∫—Ü–∏–∏ QR: {e}")
            return []

class EnhancedStampDetector:
    def __init__(self, model_path=None):
        if model_path is None:
            model_path = MODELS_DIR / 'best.pt'
        
        if not os.path.exists(model_path):
            print(f"‚ö†Ô∏è –ú–æ–¥–µ–ª—å —à—Ç–∞–º–ø–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {model_path}")
            print("   –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è YOLOv8n (fallback)...")
            self.model = YOLO('yolov8n.pt')
        else:
            print(f"‚úÖ –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ —à—Ç–∞–º–ø–æ–≤: {model_path}")
            self.model = YOLO(model_path)
        
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ñ–∏–ª—å—Ç—Ä—ã –¥–ª—è —à—Ç–∞–º–ø–æ–≤
        self.min_stamp_area = 500  # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –ø–ª–æ—â–∞–¥—å —à—Ç–∞–º–ø–∞
        self.max_stamp_area = 50000  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –ø–ª–æ—â–∞–¥—å —à—Ç–∞–º–ø–∞
    
    def detect_stamps(self, image: Image.Image) -> List[Dict]:
        start_time = time.time()
        
        if image.mode != 'RGB':
            image = image.convert('RGB')
        
        # –î–µ—Ç–µ–∫—Ü–∏—è —Å –Ω–∏–∑–∫–∏–º –ø–æ—Ä–æ–≥–æ–º —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
        results = self.model(image, conf=0.3, iou=0.4)
        detections = []
        
        for result in results:
            for box in result.boxes:
                conf = float(box.conf.item())
                if conf > 0.3:
                    x1, y1, x2, y2 = map(int, box.xyxy[0])
                    area = (x2 - x1) * (y2 - y1)
                    
                    # –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ —Ä–∞–∑–º–µ—Ä—É
                    if self.min_stamp_area <= area <= self.max_stamp_area:
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–æ—Ä–º—É (—à—Ç–∞–º–ø—ã –æ–±—ã—á–Ω–æ –∫–≤–∞–¥—Ä–∞—Ç–Ω—ã–µ/–∫—Ä—É–≥–ª—ã–µ)
                        width = x2 - x1
                        height = y2 - y1
                        aspect_ratio = width / height if height > 0 else 0
                        
                        # –®—Ç–∞–º–ø—ã –æ–±—ã—á–Ω–æ –∏–º–µ—é—Ç —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ —Å—Ç–æ—Ä–æ–Ω –±–ª–∏–∑–∫–æ–µ –∫ 1
                        if 0.5 <= aspect_ratio <= 2.0:
                            detections.append({
                                'label': 'stamp',
                                'bbox': [x1, y1, x2, y2],
                                'confidence': conf,
                                'area': area,
                                'aspect_ratio': aspect_ratio
                            })
        
        print(f"‚è±Ô∏è –î–µ—Ç–µ–∫—Ü–∏—è —à—Ç–∞–º–ø–æ–≤: {time.time() - start_time:.2f}s, –Ω–∞–π–¥–µ–Ω–æ: {len(detections)}")
        return detections

class DigitalInspector:
    def __init__(self):
        print("\n" + "="*70)
        print("üöÄ –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø –£–õ–£–ß–®–ï–ù–ù–û–ì–û DigitalInspector")
        print("="*70)
        
        self.signature_detector = AdvancedSignatureDetector()
        self.qr_detector = RobustQRCodeDetector()
        self.stamp_detector = EnhancedStampDetector()
        
        print("‚úÖ DigitalInspector –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω!\n")
    
    def process_document(self, image: Image.Image, page_num: int = 0) -> Dict:
        """–û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞"""
        start_time = time.time()
        
        print(f"\nüìÑ –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã {page_num + 1}...")
        
        # –î–µ—Ç–µ–∫—Ü–∏—è –≤—Å–µ—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤
        signatures = self.detect_signatures(image)
        qr_codes = self.detect_qr_codes(image)
        stamps = self.detect_stamps(image)
        
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–π
        processed_detections = self._resolve_overlaps(signatures, stamps, qr_codes)
        
        # –°–æ–∑–¥–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        result = {
            'page_number': page_num,
            'detections': processed_detections,
            'image_size': image.size,
            'processing_time': time.time() - start_time,
            'elements_found': {
                'signatures': len([d for d in processed_detections if d['label'] == 'signature']),
                'stamps': len([d for d in processed_detections if d['label'] == 'stamp']),
                'qr_codes': len([d for d in processed_detections if d['label'] == 'qr_code'])
            }
        }
        
        print(f"‚úÖ –°—Ç—Ä–∞–Ω–∏—Ü–∞ {page_num + 1} –æ–±—Ä–∞–±–æ—Ç–∞–Ω–∞ –∑–∞ {result['processing_time']:.2f}s")
        print(f"   üìù –ü–æ–¥–ø–∏—Å–∏: {result['elements_found']['signatures']}")
        print(f"   üè∑Ô∏è –®—Ç–∞–º–ø—ã: {result['elements_found']['stamps']}")
        print(f"   üì± QR-–∫–æ–¥—ã: {result['elements_found']['qr_codes']}")
        
        return result
    
    def _resolve_overlaps(self, signatures: List[Dict], stamps: List[Dict], qr_codes: List[Dict]) -> List[Dict]:
        """–†–∞–∑—Ä–µ—à–∞–µ—Ç –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏—è –º–µ–∂–¥—É —Ä–∞–∑–Ω—ã–º–∏ —Ç–∏–ø–∞–º–∏ –¥–µ—Ç–µ–∫—Ü–∏–π"""
        all_detections = signatures + stamps + qr_codes
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
        all_detections.sort(key=lambda x: x['confidence'], reverse=True)
        final_detections = []
        
        for detection in all_detections:
            overlap_found = False
            
            for kept in final_detections:
                iou = self._calculate_iou(detection['bbox'], kept['bbox'])
                
                # –†–∞–∑–Ω—ã–µ –ø—Ä–∞–≤–∏–ª–∞ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤ –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–π
                if iou > 0.3:
                    if detection['label'] == kept['label']:
                        # –î–ª—è –æ–¥–∏–Ω–∞–∫–æ–≤—ã—Ö —Ç–∏–ø–æ–≤ –æ—Å—Ç–∞–≤–ª—è–µ–º –±–æ–ª–µ–µ —É–≤–µ—Ä–µ–Ω–Ω—É—é
                        overlap_found = True
                        break
                    else:
                        # –î–ª—è —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤ –ø—Ä–∏–º–µ–Ω—è–µ–º –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—ã
                        if detection['label'] == 'qr_code' and kept['label'] in ['signature', 'stamp']:
                            # QR-–∫–æ–¥—ã –∏–º–µ—é—Ç –≤—ã—Å—à–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç
                            final_detections.remove(kept)
                        elif detection['label'] == 'stamp' and kept['label'] == 'signature':
                            # –®—Ç–∞–º–ø—ã –∏–º–µ—é—Ç –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç –Ω–∞–¥ –ø–æ–¥–ø–∏—Å—è–º–∏ –ø—Ä–∏ –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–∏
                            if detection['confidence'] > kept['confidence'] * 1.2:
                                final_detections.remove(kept)
                            else:
                                overlap_found = True
                                break
            
            if not overlap_found:
                final_detections.append(detection)
        
        return final_detections
    
    def _calculate_iou(self, box1: List[float], box2: List[float]) -> float:
        """–í—ã—á–∏—Å–ª—è–µ—Ç Intersection over Union"""
        x1_1, y1_1, x2_1, y2_1 = box1
        x1_2, y1_2, x2_2, y2_2 = box2
        
        xi1 = max(x1_1, x1_2)
        yi1 = max(y1_1, y1_2)
        xi2 = min(x2_1, x2_2)
        yi2 = min(y2_1, y2_2)
        inter_area = max(0, xi2 - xi1) * max(0, yi2 - yi1)
        
        box1_area = (x2_1 - x1_1) * (y2_1 - y1_1)
        box2_area = (x2_2 - x1_2) * (y2_2 - y1_2)
        union_area = box1_area + box2_area - inter_area
        
        return inter_area / union_area if union_area > 0 else 0
    
    def detect_signatures(self, image: Image.Image) -> List[Dict]:
        return self.signature_detector.detect_signatures(image)
    
    def detect_qr_codes(self, image: Image.Image) -> List[Dict]:
        return self.qr_detector.detect_qr_codes(image)
    
    def detect_stamps(self, image: Image.Image) -> List[Dict]:
        return self.stamp_detector.detect_stamps(image)
    
    def draw_detections(self, image: Image.Image, detections: List[Dict]) -> Image.Image:
        """–†–∏—Å—É–µ—Ç bounding boxes —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–µ–π"""
        opencv_image = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)
        
        colors = {
            'signature': (0, 0, 255),    # –ö—Ä–∞—Å–Ω—ã–π
            'qr_code': (0, 255, 0),      # –ó–µ–ª–µ–Ω—ã–π
            'stamp': (255, 0, 0),        # –°–∏–Ω–∏–π
        }
        
        for detection in detections:
            label = detection['label']
            bbox = detection['bbox']
            confidence = detection.get('confidence', 0)
            source = detection.get('source', 'general')
            
            color = colors.get(label, (128, 128, 128))
            x1, y1, x2, y2 = map(int, bbox)
            
            # –†–∏—Å—É–µ–º bounding box
            thickness = 4 if source == 'text_guided' else 2
            cv2.rectangle(opencv_image, (x1, y1), (x2, y2), color, thickness)
            
            # –ü–æ–¥–ø–∏—Å—å —Å —Ñ–æ–Ω–æ–º
            label_text = f"{label}: {confidence:.2f}"
            if source == 'text_guided':
                label_text += " üìù"
            
            (text_width, text_height), baseline = cv2.getTextSize(
                label_text, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2
            )
            
            # –§–æ–Ω –¥–ª—è —Ç–µ–∫—Å—Ç–∞
            cv2.rectangle(opencv_image, 
                         (x1, y1 - text_height - 10),
                         (x1 + text_width, y1), 
                         color, -1)
            
            # –¢–µ–∫—Å—Ç
            cv2.putText(opencv_image, label_text, (x1, y1 - 5),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
        
        return Image.fromarray(cv2.cvtColor(opencv_image, cv2.COLOR_BGR2RGB))
    
    def save_results_json(self, results: List[Dict], output_path: Path):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ JSON —Ñ–æ—Ä–º–∞—Ç–µ"""
        output_data = {
            'metadata': {
                'processing_time': sum(r['processing_time'] for r in results),
                'total_pages': len(results),
                'total_elements': sum(r['elements_found']['signatures'] + 
                                    r['elements_found']['stamps'] + 
                                    r['elements_found']['qr_codes'] for r in results)
            },
            'pages': []
        }
        
        for result in results:
            page_data = {
                'page_number': result['page_number'],
                'image_size': result['image_size'],
                'processing_time': result['processing_time'],
                'detections': []
            }
            
            for detection in result['detections']:
                detection_data = {
                    'label': detection['label'],
                    'bbox': detection['bbox'],
                    'confidence': round(detection['confidence'], 3)
                }
                page_data['detections'].append(detection_data)
            
            output_data['pages'].append(page_data)
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(output_data, f, ensure_ascii=False, indent=2)
        
        print(f"üíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {output_path}")

# –ì–ª–æ–±–∞–ª—å–Ω—ã–π –∏–Ω—Å—Ç–∞–Ω—Å –¥–ª—è easy access
digital_inspector = DigitalInspector()
